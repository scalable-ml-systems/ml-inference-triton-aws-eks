ğŸ—ï¸ Core Infrastructure

AWS EKS Cluster â€“ managed Kubernetes control plane

GPU Node Group â€“ EC2 G4/G5 or P-series instances for Triton inference

CPU Node Group â€“ EC2 M5.large/M5.xlarge for regular workloads, CI/CD, and monitoring

VPC + Subnets + Security Groups â€“ isolated networking with secure routing

IAM Roles & Policies â€“ fine-grained access control for nodes and services

Storage:

Amazon EFS â€“ shared persistent storage for models

Amazon S3 â€“ artifact and model repository

âš™ï¸ Kubernetes Layer

Helm â€“ package manager for deploying charts (Triton, monitoring, CI/CD)

Ingress / API Gateway â€“ expose inference endpoints

Istio (minimal service mesh) â€“ secure, observable communication between services

PVCs & StorageClass â€“ persistent volume management for model storage

ğŸ“¦ ML Serving

NVIDIA Triton Inference Server â€“ scalable model deployment

Model Repository â€“ ECR or S3 for storing and versioning models

ONNX / TensorRT / PyTorch models â€“ standardized formats for inference

ğŸ” Observability & Monitoring

Prometheus â€“ metrics collection (GPU utilization, pod health, latency)

Grafana â€“ dashboards for inference performance and resource usage

Loki / Fluentd â€“ centralized logging

Alertmanager â€“ proactive alerts

DCGM Exporter â€“ NVIDIA GPU metrics exporter for Prometheus

nvidia-smi â€“ GPU diagnostics inside pods/nodes

ğŸ“‚ Storage Plugins

EFS CSI Driver â€“ mount EFS volumes into pods

PersistentVolume / PersistentVolumeClaim â€“ bind workloads to storage

ğŸŒ Networking

Amazon VPC CNI â€“ baseline pod networking in EKS

Calico (optional) â€“ network policies for zero-trust isolation

CNI Metrics Helper â€“ expose CNI metrics to Prometheus

Network Policies â€“ enforce namespace-level traffic rules

ğŸš€ CI/CD & Automation

GitHub Actions â€“ deploy/destroy pipelines (ci/github-actions/deploy-infra.yaml, destroy-infra.yaml)

Terraform â€“ reproducible infrastructure provisioning (EKS, VPC, node groups, storage)

ArgoCD / Flux â€“ GitOps for Kubernetes manifests

Repo Hygiene â€“ .gitignore for sensitive files (*.tfstate, *.tfvars, *.pem, *.onnx)

ğŸ” Security & Compliance

AWS Secrets Manager / KMS â€“ manage sensitive configs and certificates

RBAC in Kubernetes â€“ role-based access control

Pod Security Policies / OPA Gatekeeper â€“ enforce compliance

Network Policies â€“ restrict pod-to-pod communication

ğŸ“š Documentation & Onboarding

README.md â€“ technical value statement and quickstart

Architecture Diagrams â€“ AWS + Kubernetes + Triton flow (EdrawMax/Lucidchart)

Runbooks â€“ GPU provisioning, PVC hygiene, EFS mounting, CI/CD troubleshooting

Onboarding Guides â€“ step-by-step setup for engineers

ğŸ“ Provision Order (Essential to Follow)

It is essential to follow this order to ensure reproducibility, teardown hygiene, and correct dependency resolution:

Initialize Terraform

terraform init


Provision Core Infrastructure

VPC, Subnets, Security Groups

IAM Roles & Policies

EKS Cluster

Add Node Groups

GPU node group (Triton inference)

CPU node group (regular workloads)

Install CNI Plugins

Amazon VPC CNI

Calico (optional, for network policies)

CNI Metrics Helper

Install Storage Plugins

EFS CSI Driver

Configure PersistentVolumes and PersistentVolumeClaims

Deploy Observability Stack

Prometheus, Grafana, Loki, Alertmanager

DCGM Exporter for GPU metrics

Deploy NVIDIA Triton Inference Server

Connect to model repository (ECR/S3)

Configure Istio Service Mesh

Secure communication between microservices

Set Up CI/CD Pipelines

GitHub Actions for infra deploy/destroy

ArgoCD / Flux for GitOps

Finalize Documentation

README, diagrams, runbooks, onboarding guides

âœ… Summary

This stack ensures:

Compute â€“ GPU + CPU node groups

Storage â€“ EFS CSI + S3

Networking â€“ VPC CNI + Calico

Monitoring â€“ Prometheus, Grafana, DCGM Exporter, nvidia-smi

Automation â€“ Terraform + GitHub Actions + GitOps
